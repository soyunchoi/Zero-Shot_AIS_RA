"""
VLM-SAM í†µí•© ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹œê°í™”í•˜ëŠ” ëª¨ë“ˆ
Attention Map â†’ Point Sampling â†’ SAM Prediction ì „ì²´ ê³¼ì •ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from typing import Dict, Tuple, Optional


class IntegratedVisualizer:
    """VLM-SAM í†µí•© ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """IntegratedVisualizer ì´ˆê¸°í™”"""
        print("IntegratedVisualizer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def visualize_complete_pipeline(self,
                                  image: np.ndarray,
                                  attention_maps: Dict,
                                  aggregated_attention: np.ndarray,
                                  sam_points: np.ndarray,
                                  sam_labels: np.ndarray,
                                  pred_amodal_mask: np.ndarray,
                                  pred_visible_mask: np.ndarray,
                                  gt_amodal_mask: Optional[np.ndarray] = None,
                                  gt_visible_mask: Optional[np.ndarray] = None,
                                  bbox: Optional[np.ndarray] = None,
                                  save_path: str = None,
                                  title: str = "VLM-SAM Pipeline") -> None:
        """
        VLM-SAM ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€ (H, W, 3)
            attention_maps: Layerë³„ attention maps
            aggregated_attention: ì§‘ê³„ëœ attention map (H, W)
            sam_points: SAM prompt points (N, 2)
            sam_labels: SAM prompt labels (N,)
            pred_amodal_mask: ì˜ˆì¸¡ëœ amodal mask (H, W)
            pred_visible_mask: ì˜ˆì¸¡ëœ visible mask (H, W)
            gt_amodal_mask: GT amodal mask (optional)
            gt_visible_mask: GT visible mask (optional)
            bbox: ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2] (optional)
            save_path: ì €ì¥ ê²½ë¡œ
            title: ì œëª©
        """
        
        print(f"ğŸ¨ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ìƒì„±: {title}")
        
        # ì„œë¸Œí”Œë¡¯ êµ¬ì„± (2í–‰ 4ì—´)
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€ + ë°”ìš´ë”© ë°•ìŠ¤
        axes[0, 0].imshow(image)
        if bbox is not None:
            rect = plt.Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1], 
                               fill=False, color='red', linewidth=2)
            axes[0, 0].add_patch(rect)
        axes[0, 0].set_title('1. Original Image + BBox')
        axes[0, 0].axis('off')
        
        # 2. Aggregated Attention Map
        im2 = axes[0, 1].imshow(aggregated_attention, cmap='jet')
        axes[0, 1].set_title('2. VLM Attention Map')
        axes[0, 1].axis('off')
        plt.colorbar(im2, ax=axes[0, 1], fraction=0.046)
        
        # 3. Attention Map + Sampled Points
        axes[0, 2].imshow(image, alpha=0.7)
        axes[0, 2].imshow(aggregated_attention, cmap='jet', alpha=0.5)
        
        # SAM points ì‹œê°í™”
        if len(sam_points) > 0:
            positive_points = sam_points[sam_labels == 1]
            negative_points = sam_points[sam_labels == 0]
            
            if len(positive_points) > 0:
                axes[0, 2].scatter(positive_points[:, 0], positive_points[:, 1], 
                                 c='red', s=100, marker='o', edgecolors='white', linewidth=2,
                                 label=f'Positive ({len(positive_points)})')
            
            if len(negative_points) > 0:
                axes[0, 2].scatter(negative_points[:, 0], negative_points[:, 1], 
                                 c='blue', s=100, marker='x', linewidth=3,
                                 label=f'Negative ({len(negative_points)})')
            
            axes[0, 2].legend()
        
        axes[0, 2].set_title('3. Attention + SAM Points')
        axes[0, 2].axis('off')
        
        # 4. ì˜ˆì¸¡ëœ Amodal Mask
        axes[0, 3].imshow(image, alpha=0.7)
        im4 = axes[0, 3].imshow(pred_amodal_mask, alpha=0.6, cmap='Reds')
        axes[0, 3].set_title('4. Predicted Amodal Mask')
        axes[0, 3].axis('off')
        
        # 5. ì˜ˆì¸¡ëœ Visible Mask
        axes[1, 0].imshow(image, alpha=0.7)
        im5 = axes[1, 0].imshow(pred_visible_mask, alpha=0.6, cmap='Blues')
        axes[1, 0].set_title('5. Predicted Visible Mask')
        axes[1, 0].axis('off')
        
        # 6. Amodal vs Visible ë¹„êµ
        axes[1, 1].imshow(image, alpha=0.7)
        axes[1, 1].imshow(pred_amodal_mask, alpha=0.4, cmap='Reds', label='Amodal')
        axes[1, 1].imshow(pred_visible_mask, alpha=0.4, cmap='Blues', label='Visible')
        axes[1, 1].set_title('6. Amodal (Red) vs Visible (Blue)')
        axes[1, 1].axis('off')
        
        # 7. GTì™€ ë¹„êµ (GTê°€ ìˆëŠ” ê²½ìš°)
        if gt_amodal_mask is not None and gt_visible_mask is not None:
            axes[1, 2].imshow(image, alpha=0.7)
            axes[1, 2].imshow(gt_amodal_mask, alpha=0.3, cmap='Greens', label='GT Amodal')
            axes[1, 2].imshow(pred_amodal_mask, alpha=0.3, cmap='Reds', label='Pred Amodal')
            axes[1, 2].set_title('7. GT (Green) vs Pred (Red)')
            axes[1, 2].axis('off')
        else:
            # GTê°€ ì—†ìœ¼ë©´ Invisible ì˜ì—­ ì‹œê°í™”
            invisible_mask = np.clip(pred_amodal_mask - pred_visible_mask, 0, 1)
            axes[1, 2].imshow(image, alpha=0.7)
            axes[1, 2].imshow(invisible_mask, alpha=0.6, cmap='Purples')
            axes[1, 2].set_title('7. Predicted Invisible Region')
            axes[1, 2].axis('off')
        
        # 8. í†µê³„ ì •ë³´
        axes[1, 3].axis('off')
        
        # í†µê³„ í…ìŠ¤íŠ¸ ìƒì„±
        stats_text = []
        stats_text.append(f"VLM-SAM Pipeline Statistics")
        stats_text.append(f"=" * 30)
        stats_text.append(f"Attention Layers: {len(attention_maps)}")
        stats_text.append(f"Attention Mean: {np.mean(aggregated_attention):.3f}")
        stats_text.append(f"Attention Std: {np.std(aggregated_attention):.3f}")
        stats_text.append(f"")
        stats_text.append(f"SAM Prompts:")
        stats_text.append(f"  Total Points: {len(sam_points)}")
        stats_text.append(f"  Positive: {np.sum(sam_labels)}")
        stats_text.append(f"  Negative: {len(sam_points) - np.sum(sam_labels)}")
        stats_text.append(f"")
        stats_text.append(f"Predictions:")
        stats_text.append(f"  Amodal Coverage: {np.mean(pred_amodal_mask):.3f}")
        stats_text.append(f"  Visible Coverage: {np.mean(pred_visible_mask):.3f}")
        
        if gt_amodal_mask is not None:
            # IoU ê³„ì‚°
            amodal_iou = self._calculate_iou(pred_amodal_mask, gt_amodal_mask)
            visible_iou = self._calculate_iou(pred_visible_mask, gt_visible_mask)
            stats_text.append(f"")
            stats_text.append(f"Performance:")
            stats_text.append(f"  Amodal IoU: {amodal_iou:.3f}")
            stats_text.append(f"  Visible IoU: {visible_iou:.3f}")
        
        # í…ìŠ¤íŠ¸ í‘œì‹œ
        axes[1, 3].text(0.05, 0.95, '\n'.join(stats_text), 
                        transform=axes[1, 3].transAxes, fontsize=10,
                        verticalalignment='top', fontfamily='monospace',
                        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        axes[1, 3].set_title('8. Pipeline Statistics')
        
        # ì „ì²´ ì œëª©
        plt.suptitle(title, fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ì €ì¥
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ“ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ì €ì¥: {save_path}")
        
        plt.close()
    
    def _calculate_iou(self, pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:
        """IoU ê³„ì‚°"""
        # ì´ì§„í™”
        pred_binary = (pred_mask > 0.5).astype(float)
        gt_binary = (gt_mask > 0.5).astype(float)
        
        # IoU ê³„ì‚°
        intersection = np.sum(pred_binary * gt_binary)
        union = np.sum(pred_binary) + np.sum(gt_binary) - intersection
        
        if union == 0:
            return 0.0
        
        return intersection / union
    
    def create_attention_analysis(self,
                                attention_maps: Dict,
                                aggregated_attention: np.ndarray,
                                save_path: str = None) -> None:
        """
        Attention Map ë¶„ì„ ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            attention_maps: Layerë³„ attention maps
            aggregated_attention: ì§‘ê³„ëœ attention map
            save_path: ì €ì¥ ê²½ë¡œ
        """
        
        print("ğŸ§  Attention Map ë¶„ì„ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        num_layers = len(attention_maps)
        if num_layers == 0:
            print("âš ï¸ Attention mapsê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„œë¸Œí”Œë¡¯ êµ¬ì„±
        cols = min(4, num_layers + 1)
        rows = (num_layers + 1 + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))
        if rows == 1:
            axes = axes.reshape(1, -1)
        
        # Layerë³„ attention maps
        for i, (layer_name, attention_map) in enumerate(attention_maps.items()):
            row = i // cols
            col = i % cols
            
            im = axes[row, col].imshow(attention_map, cmap='jet')
            axes[row, col].set_title(f'{layer_name}\nMean: {np.mean(attention_map):.3f}')
            axes[row, col].axis('off')
            plt.colorbar(im, ax=axes[row, col], fraction=0.046)
        
        # ì§‘ê³„ëœ attention map
        final_row = (num_layers) // cols
        final_col = (num_layers) % cols
        
        im_final = axes[final_row, final_col].imshow(aggregated_attention, cmap='jet')
        axes[final_row, final_col].set_title(f'Aggregated\nMean: {np.mean(aggregated_attention):.3f}')
        axes[final_row, final_col].axis('off')
        plt.colorbar(im_final, ax=axes[final_row, final_col], fraction=0.046)
        
        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
        for i in range(num_layers + 1, rows * cols):
            row = i // cols
            col = i % cols
            axes[row, col].axis('off')
        
        plt.suptitle('VLM Attention Maps Analysis', fontsize=14)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ“ Attention ë¶„ì„ ì‹œê°í™” ì €ì¥: {save_path}")
        
        plt.close()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == '__main__':
    print("=== IntegratedVisualizer í…ŒìŠ¤íŠ¸ ===")
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    attention_maps = {
        'layer_26': np.random.rand(224, 224),
        'layer_27': np.random.rand(224, 224),
        'layer_28': np.random.rand(224, 224),
    }
    aggregated_attention = np.mean(list(attention_maps.values()), axis=0)
    sam_points = np.array([[100, 100], [150, 150], [50, 180]])
    sam_labels = np.array([1, 1, 0])
    pred_amodal = np.random.rand(224, 224)
    pred_visible = np.random.rand(224, 224) * 0.8
    bbox = np.array([50, 50, 200, 200])
    
    # ì‹œê°í™” ìƒì„±
    visualizer = IntegratedVisualizer()
    
    # ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
    visualizer.visualize_complete_pipeline(
        image, attention_maps, aggregated_attention,
        sam_points, sam_labels, pred_amodal, pred_visible,
        bbox=bbox, save_path="./test_pipeline_visualization.png",
        title="Test VLM-SAM Pipeline"
    )
    
    # Attention ë¶„ì„ ì‹œê°í™”
    visualizer.create_attention_analysis(
        attention_maps, aggregated_attention,
        save_path="./test_attention_analysis.png"
    )
    
    print("âœ… IntegratedVisualizer í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
