"""
D2SA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ VLM-SAM í†µí•© ì‹œìŠ¤í…œ ì¢…í•© ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
- VLM occlusion ë¶„ì„ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
- ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•œ ì‹œê°í™” ê²°ê³¼ ì €ì¥
- ì •ëŸ‰ì  ì„±ëŠ¥ í‰ê°€ ë° í†µê³„ ë¶„ì„
"""

import os
import json
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from datetime import datetime
from tqdm import tqdm
import traceback
from typing import Dict, List, Tuple, Optional

from vlm_sam_model import VLMSAMModel
from d2sa_dataset import D2SADataset


class D2SAExperiment:
    """D2SA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œ VLM-SAM ì‹¤í—˜ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 annotation_file: str,
                 image_dir: str,
                 output_dir: str = "./outputs/d2sa_experiment",
                 max_samples: Optional[int] = None):
        """
        ì‹¤í—˜ ì´ˆê¸°í™”
        
        Args:
            annotation_file: D2SA ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ
            image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            max_samples: ìµœëŒ€ ì²˜ë¦¬í•  ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        """
        self.annotation_file = annotation_file
        self.image_dir = image_dir
        self.output_dir = output_dir
        self.max_samples = max_samples
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ì„œë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.viz_dir = os.path.join(output_dir, "visualizations")
        self.results_dir = os.path.join(output_dir, "results")
        self.analysis_dir = os.path.join(output_dir, "analysis")
        
        for dir_path in [self.viz_dir, self.results_dir, self.analysis_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        # ì‹¤í—˜ ë©”íƒ€ë°ì´í„°
        self.experiment_info = {
            "start_time": datetime.now().isoformat(),
            "annotation_file": annotation_file,
            "image_dir": image_dir,
            "max_samples": max_samples,
            "output_dir": output_dir
        }
        
        print(f"=== D2SA ì‹¤í—˜ ì´ˆê¸°í™” ì™„ë£Œ ===")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        print(f"ğŸ“Š ìµœëŒ€ ìƒ˜í”Œ ìˆ˜: {max_samples or 'ì „ì²´'}")
    
    def load_dataset(self):
        """D2SA ë°ì´í„°ì…‹ ë¡œë“œ"""
        print("\nğŸ“Š D2SA ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
        
        try:
            # ë°ì´í„°ì…‹ì— transform ì¶”ê°€í•˜ì—¬ í…ì„œë¡œ ë³€í™˜
            from torchvision import transforms
            
            transform = transforms.Compose([
                transforms.Resize((1024, 1024)),
                transforms.ToTensor(),
            ])
            
            self.dataset = D2SADataset(
                annotation_file=self.annotation_file,
                image_dir=self.image_dir,
                transform=transform,
                max_samples=self.max_samples
            )
            
            print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ: {len(self.dataset)}ê°œ ìƒ˜í”Œ")
            
            # ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥
            dataset_info = {
                "total_samples": len(self.dataset),
                "annotation_file": self.annotation_file,
                "image_dir": self.image_dir
            }
            
            with open(os.path.join(self.results_dir, "dataset_info.json"), 'w') as f:
                json.dump(dataset_info, f, indent=2, ensure_ascii=False)
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return False
    
    def load_model(self):
        """VLM-SAM ëª¨ë¸ ë¡œë“œ"""
        print("\nğŸ¤– VLM-SAM ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
        try:
            self.model = VLMSAMModel()
            print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return False
    
    def get_category_name(self, category_id: int) -> str:
        """ì¹´í…Œê³ ë¦¬ IDë¥¼ ì¹´í…Œê³ ë¦¬ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        # COCO ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (D2SAì—ì„œ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ì¹´í…Œê³ ë¦¬ë“¤)
        category_map = {
            1: "person", 2: "bicycle", 3: "car", 4: "motorcycle", 5: "airplane",
            6: "bus", 7: "train", 8: "truck", 9: "boat", 10: "traffic light",
            11: "fire hydrant", 13: "stop sign", 14: "parking meter", 15: "bench",
            16: "bird", 17: "cat", 18: "dog", 19: "horse", 20: "sheep",
            21: "cow", 22: "elephant", 23: "bear", 24: "zebra", 25: "giraffe",
            27: "backpack", 28: "umbrella", 31: "handbag", 32: "tie",
            33: "suitcase", 34: "frisbee", 35: "skis", 36: "snowboard",
            37: "sports ball", 38: "kite", 39: "baseball bat", 40: "baseball glove",
            41: "skateboard", 42: "surfboard", 43: "tennis racket", 44: "bottle",
            46: "wine glass", 47: "cup", 48: "fork", 49: "knife", 50: "spoon",
            51: "bowl", 52: "banana", 53: "apple", 54: "sandwich", 55: "orange",
            56: "broccoli", 57: "carrot", 58: "hot dog", 59: "pizza", 60: "donut",
            61: "cake", 62: "chair", 63: "couch", 64: "potted plant", 65: "bed",
            67: "dining table", 70: "toilet", 72: "tv", 73: "laptop", 74: "mouse",
            75: "remote", 76: "keyboard", 77: "cell phone", 78: "microwave",
            79: "oven", 80: "toaster", 81: "sink", 82: "refrigerator", 84: "book",
            85: "clock", 86: "vase", 87: "scissors", 88: "teddy bear", 89: "hair drier",
            90: "toothbrush"
        }
        
        return category_map.get(category_id, f"category_{category_id}")
    
    def run_single_sample(self, idx: int) -> Dict:
        """ë‹¨ì¼ ìƒ˜í”Œì— ëŒ€í•œ ì‹¤í—˜ ìˆ˜í–‰"""
        try:
            # ë°ì´í„° ë¡œë“œ (D2SADatasetì€ íŠœí”Œì„ ë°˜í™˜)
            data = self.dataset[idx]
            image, bbox, text, amodal_mask, visible_mask, invisible_mask, annotation_info = data
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° í˜•ë³€í™˜
            image_tensor = image.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            box = bbox.unsqueeze(0)
            
            # PIL ì´ë¯¸ì§€ ìƒì„± (ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ)
            image_np = (image.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
            pil_image = Image.fromarray(image_np)
            
            # ë§ˆìŠ¤í¬ë¥¼ numpyë¡œ ë³€í™˜
            amodal_mask = amodal_mask.squeeze().cpu().numpy()
            visible_mask = visible_mask.squeeze().cpu().numpy()
            
            # ì–´ë…¸í…Œì´ì…˜ ì •ë³´ì—ì„œ ì¶”ì¶œ
            image_id = annotation_info['image_id'].item()
            category_id = annotation_info['category_id'].item()
            
            # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë³€í™˜
            target_class = self.get_category_name(category_id)
            
            print(f"  ğŸ“¸ ì´ë¯¸ì§€ ID: {image_id}")
            print(f"  ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {target_class} (ID: {category_id})")
            print(f"  ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
            print(f"  ğŸ“¦ ë°”ìš´ë”© ë°•ìŠ¤: {box[0].cpu().numpy()}")
            
            # VLM-SAM íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            print(f"  ğŸ”„ VLM-SAM íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
            
            with torch.no_grad():
                results = self.model(
                    image=image_tensor,
                    box=box,
                    image_pil=pil_image,
                    text=target_class
                )
            
            # ê²°ê³¼ ì–¸íŒ¨í‚¹
            pred_amodal, pred_amodal_iou, pred_visible, pred_visible_iou, occlusion_info, attention_maps, aggregated_attention, sam_points, sam_labels = results
            
            # IoU ê³„ì‚°
            amodal_iou = self._calculate_iou(
                torch.sigmoid(pred_amodal[0]).squeeze().cpu().numpy(),
                amodal_mask
            )
            visible_iou = self._calculate_iou(
                torch.sigmoid(pred_visible[0]).squeeze().cpu().numpy(),
                visible_mask
            )
            
            print(f"  âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"    - Attention layers: {len(attention_maps)}ê°œ")
            print(f"    - SAM points: {len(sam_points)}ê°œ")
            print(f"    - Amodal IoU: {amodal_iou:.3f}")
            print(f"    - Visible IoU: {visible_iou:.3f}")
            
            # ì‹œê°í™” ìƒì„±
            viz_path = os.path.join(self.viz_dir, f"sample_{idx:04d}_{image_id}_{target_class}.png")
            
            self.model.create_pipeline_visualization(
                image_pil=pil_image,
                results=results,
                bbox=box[0].cpu().numpy(),
                gt_amodal=amodal_mask,
                gt_visible=visible_mask,
                save_path=viz_path,
                title=f"Sample {idx} - {target_class} (ID: {image_id})"
            )
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            sample_result = {
                "sample_idx": idx,
                "image_id": str(image_id),
                "category_id": int(category_id),
                "category_name": target_class,
                "image_shape": image.shape[2:],  # (H, W)
                "bbox": box[0].cpu().numpy().tolist(),
                
                # VLM ë¶„ì„ ê²°ê³¼
                "vlm_analysis": {
                    "visible_objects": occlusion_info.get("visible_objects", []),
                    "occluded_objects": occlusion_info.get("occluded_objects", []),
                    "occlusion_relations": occlusion_info.get("occlusion_relations", [])
                },
                
                # Attention ì •ë³´
                "attention_info": {
                    "num_layers": len(attention_maps),
                    "aggregated_stats": {
                        "mean": float(np.mean(aggregated_attention)),
                        "std": float(np.std(aggregated_attention)),
                        "min": float(np.min(aggregated_attention)),
                        "max": float(np.max(aggregated_attention))
                    }
                },
                
                # Point Sampling ê²°ê³¼
                "point_sampling": {
                    "total_points": len(sam_points),
                    "positive_points": int(np.sum(sam_labels)),
                    "negative_points": int(len(sam_points) - np.sum(sam_labels)),
                    "points": sam_points.tolist() if len(sam_points) > 0 else [],
                    "labels": sam_labels.tolist() if len(sam_labels) > 0 else []
                },
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­
                "performance": {
                    "amodal_iou": float(amodal_iou),
                    "visible_iou": float(visible_iou),
                    "pred_amodal_iou": float(pred_amodal_iou[0].item()),
                    "pred_visible_iou": float(pred_visible_iou[0].item())
                },
                
                # íŒŒì¼ ê²½ë¡œ
                "visualization_path": viz_path,
                
                # ì²˜ë¦¬ ìƒíƒœ
                "status": "success",
                "error": None
            }
            
            return sample_result
            
        except Exception as e:
            print(f"  âŒ ìƒ˜í”Œ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            
            # ì˜¤ë¥˜ ê²°ê³¼ ë°˜í™˜
            image_id = 'unknown'
            try:
                if 'data' in locals() and len(data) >= 7:
                    annotation_info = data[6]
                    if isinstance(annotation_info, dict) and 'image_id' in annotation_info:
                        image_id = str(annotation_info['image_id'].item())
            except:
                pass
            
            error_result = {
                "sample_idx": idx,
                "image_id": image_id,
                "status": "error",
                "error": str(e),
                "traceback": traceback.format_exc()
            }
            
            return error_result
    
    def _calculate_iou(self, pred_mask: np.ndarray, gt_mask: np.ndarray) -> float:
        """IoU ê³„ì‚°"""
        # ì´ì§„í™”
        pred_binary = (pred_mask > 0.5).astype(float)
        gt_binary = (gt_mask > 0.5).astype(float)
        
        # IoU ê³„ì‚°
        intersection = np.sum(pred_binary * gt_binary)
        union = np.sum(pred_binary) + np.sum(gt_binary) - intersection
        
        if union == 0:
            return 0.0
        
        return intersection / union
    
    def run_experiment(self):
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        print(f"\nğŸš€ D2SA ì‹¤í—˜ ì‹œì‘")
        print(f"=" * 60)
        
        # ë°ì´í„°ì…‹ ë° ëª¨ë¸ ë¡œë“œ
        if not self.load_dataset():
            return False
        
        if not self.load_model():
            return False
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        all_results = []
        successful_samples = 0
        failed_samples = 0
        
        # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ tqdm
        total_samples = len(self.dataset)
        
        print(f"\nğŸ“Š {total_samples}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì‹œì‘...")
        
        for idx in tqdm(range(total_samples), desc="Processing samples"):
            print(f"\n--- ìƒ˜í”Œ {idx+1}/{total_samples} ---")
            
            # ë‹¨ì¼ ìƒ˜í”Œ ì²˜ë¦¬
            result = self.run_single_sample(idx)
            all_results.append(result)
            
            if result["status"] == "success":
                successful_samples += 1
            else:
                failed_samples += 1
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (10ê°œë§ˆë‹¤)
            if (idx + 1) % 10 == 0:
                temp_results_path = os.path.join(self.results_dir, f"temp_results_{idx+1}.json")
                with open(temp_results_path, 'w') as f:
                    json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ëª¨ë“  ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"  - ì„±ê³µ: {successful_samples}ê°œ")
        print(f"  - ì‹¤íŒ¨: {failed_samples}ê°œ")
        print(f"  - ì„±ê³µë¥ : {successful_samples/total_samples*100:.1f}%")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        self.save_results(all_results)
        
        # í†µê³„ ë¶„ì„ ìˆ˜í–‰
        self.analyze_results(all_results)
        
        return True
    
    def save_results(self, all_results: List[Dict]):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.experiment_info.update({
            "end_time": datetime.now().isoformat(),
            "total_samples": len(all_results),
            "successful_samples": sum(1 for r in all_results if r["status"] == "success"),
            "failed_samples": sum(1 for r in all_results if r["status"] == "error")
        })
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        final_results = {
            "experiment_info": self.experiment_info,
            "results": all_results
        }
        
        results_path = os.path.join(self.results_dir, "d2sa_experiment_results.json")
        with open(results_path, 'w') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ì „ì²´ ê²°ê³¼ ì €ì¥: {results_path}")
        
        # ì„±ê³µí•œ ìƒ˜í”Œë§Œ ë”°ë¡œ ì €ì¥
        successful_results = [r for r in all_results if r["status"] == "success"]
        if successful_results:
            success_path = os.path.join(self.results_dir, "successful_results.json")
            with open(success_path, 'w') as f:
                json.dump(successful_results, f, indent=2, ensure_ascii=False)
            print(f"âœ… ì„±ê³µ ê²°ê³¼ ì €ì¥: {success_path}")
        
        # ì‹¤íŒ¨í•œ ìƒ˜í”Œ ë¡œê·¸ ì €ì¥
        failed_results = [r for r in all_results if r["status"] == "error"]
        if failed_results:
            error_path = os.path.join(self.results_dir, "error_log.json")
            with open(error_path, 'w') as f:
                json.dump(failed_results, f, indent=2, ensure_ascii=False)
            print(f"âš ï¸ ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: {error_path}")
    
    def analyze_results(self, all_results: List[Dict]):
        """ê²°ê³¼ í†µê³„ ë¶„ì„"""
        print(f"\nğŸ“ˆ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        successful_results = [r for r in all_results if r["status"] == "success"]
        
        if not successful_results:
            print("âš ï¸ ì„±ê³µí•œ ìƒ˜í”Œì´ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        # ì„±ëŠ¥ í†µê³„
        amodal_ious = [r["performance"]["amodal_iou"] for r in successful_results]
        visible_ious = [r["performance"]["visible_iou"] for r in successful_results]
        
        # VLM ë¶„ì„ í†µê³„
        vlm_stats = {
            "total_visible_objects": 0,
            "total_occluded_objects": 0,
            "total_occlusion_relations": 0,
            "visible_object_types": {},
            "occluded_object_types": {},
            "category_performance": {}
        }
        
        for result in successful_results:
            vlm = result["vlm_analysis"]
            
            # ê°ì²´ ìˆ˜ ì§‘ê³„
            vlm_stats["total_visible_objects"] += len(vlm.get("visible_objects", []))
            vlm_stats["total_occluded_objects"] += len(vlm.get("occluded_objects", []))
            vlm_stats["total_occlusion_relations"] += len(vlm.get("occlusion_relations", []))
            
            # ê°ì²´ íƒ€ì…ë³„ ì§‘ê³„
            for obj in vlm.get("visible_objects", []):
                vlm_stats["visible_object_types"][obj] = vlm_stats["visible_object_types"].get(obj, 0) + 1
            
            for obj in vlm.get("occluded_objects", []):
                vlm_stats["occluded_object_types"][obj] = vlm_stats["occluded_object_types"].get(obj, 0) + 1
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥
            category = result["category_name"]
            if category not in vlm_stats["category_performance"]:
                vlm_stats["category_performance"][category] = {
                    "count": 0,
                    "amodal_iou_sum": 0,
                    "visible_iou_sum": 0
                }
            
            vlm_stats["category_performance"][category]["count"] += 1
            vlm_stats["category_performance"][category]["amodal_iou_sum"] += result["performance"]["amodal_iou"]
            vlm_stats["category_performance"][category]["visible_iou_sum"] += result["performance"]["visible_iou"]
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ê³„ì‚°
        for category, stats in vlm_stats["category_performance"].items():
            if stats["count"] > 0:
                stats["avg_amodal_iou"] = stats["amodal_iou_sum"] / stats["count"]
                stats["avg_visible_iou"] = stats["visible_iou_sum"] / stats["count"]
        
        # ì „ì²´ í†µê³„
        analysis_results = {
            "performance_statistics": {
                "amodal_iou": {
                    "mean": float(np.mean(amodal_ious)),
                    "std": float(np.std(amodal_ious)),
                    "min": float(np.min(amodal_ious)),
                    "max": float(np.max(amodal_ious)),
                    "median": float(np.median(amodal_ious))
                },
                "visible_iou": {
                    "mean": float(np.mean(visible_ious)),
                    "std": float(np.std(visible_ious)),
                    "min": float(np.min(visible_ious)),
                    "max": float(np.max(visible_ious)),
                    "median": float(np.median(visible_ious))
                }
            },
            "vlm_analysis_statistics": vlm_stats,
            "point_sampling_statistics": {
                "avg_total_points": float(np.mean([r["point_sampling"]["total_points"] for r in successful_results])),
                "avg_positive_points": float(np.mean([r["point_sampling"]["positive_points"] for r in successful_results])),
                "avg_negative_points": float(np.mean([r["point_sampling"]["negative_points"] for r in successful_results]))
            }
        }
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        analysis_path = os.path.join(self.analysis_dir, "experiment_analysis.json")
        with open(analysis_path, 'w') as f:
            json.dump(analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {analysis_path}")
        
        # ì½˜ì†”ì— ì£¼ìš” í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š ì£¼ìš” í†µê³„:")
        print(f"  ğŸ¯ í‰ê·  Amodal IoU: {analysis_results['performance_statistics']['amodal_iou']['mean']:.3f}")
        print(f"  ğŸ¯ í‰ê·  Visible IoU: {analysis_results['performance_statistics']['visible_iou']['mean']:.3f}")
        print(f"  ğŸ‘ï¸ í‰ê·  ë°œê²¬ëœ ë³´ì´ëŠ” ê°ì²´: {vlm_stats['total_visible_objects']/len(successful_results):.1f}ê°œ")
        print(f"  ğŸ«¥ í‰ê·  ë°œê²¬ëœ ê°€ë ¤ì§„ ê°ì²´: {vlm_stats['total_occluded_objects']/len(successful_results):.1f}ê°œ")
        print(f"  ğŸ¯ í‰ê·  SAM Points: {analysis_results['point_sampling_statistics']['avg_total_points']:.1f}ê°œ")
    
    def create_summary_report(self):
        """ì‹¤í—˜ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        print(f"\nğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ìƒì„±ëœ íŒŒì¼ë“¤ ì •ë³´ ìˆ˜ì§‘
        viz_files = [f for f in os.listdir(self.viz_dir) if f.endswith('.png')]
        result_files = [f for f in os.listdir(self.results_dir) if f.endswith('.json')]
        
        report_content = f"""# D2SA ì‹¤í—˜ ê²°ê³¼ ë³´ê³ ì„œ

## ì‹¤í—˜ ì •ë³´
- ì‹œì‘ ì‹œê°„: {self.experiment_info['start_time']}
- ì–´ë…¸í…Œì´ì…˜ íŒŒì¼: {self.annotation_file}
- ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {self.image_dir}
- ìµœëŒ€ ìƒ˜í”Œ ìˆ˜: {self.max_samples or 'ì „ì²´'}

## ìƒì„±ëœ ê²°ê³¼ë¬¼
- ì‹œê°í™” íŒŒì¼: {len(viz_files)}ê°œ
- ê²°ê³¼ JSON íŒŒì¼: {len(result_files)}ê°œ
- ì´ ì¶œë ¥ í¬ê¸°: {self._get_directory_size(self.output_dir):.1f} MB

## ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
{self.output_dir}/
â”œâ”€â”€ visualizations/     # ëª¨ë“  ìƒ˜í”Œì˜ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
â”œâ”€â”€ results/           # JSON ê²°ê³¼ íŒŒì¼ë“¤
â””â”€â”€ analysis/          # í†µê³„ ë¶„ì„ ê²°ê³¼
```

## ì£¼ìš” íŒŒì¼
- `results/d2sa_experiment_results.json`: ì „ì²´ ì‹¤í—˜ ê²°ê³¼
- `results/successful_results.json`: ì„±ê³µí•œ ìƒ˜í”Œë“¤ë§Œ
- `analysis/experiment_analysis.json`: í†µê³„ ë¶„ì„ ê²°ê³¼
- `visualizations/`: ê° ìƒ˜í”Œë³„ 8-panel íŒŒì´í”„ë¼ì¸ ì‹œê°í™”

## ì‚¬ìš© ë°©ë²•
ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ë ¤ë©´:
```python
import json

# ì „ì²´ ê²°ê³¼ ë¡œë“œ
with open('{os.path.join(self.results_dir, "d2sa_experiment_results.json")}', 'r') as f:
    results = json.load(f)

# ë¶„ì„ ê²°ê³¼ ë¡œë“œ  
with open('{os.path.join(self.analysis_dir, "experiment_analysis.json")}', 'r') as f:
    analysis = json.load(f)
```
"""
        
        report_path = os.path.join(self.output_dir, "README.md")
        with open(report_path, 'w') as f:
            f.write(report_content)
        
        print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ì €ì¥: {report_path}")
    
    def _get_directory_size(self, directory: str) -> float:
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (MB ë‹¨ìœ„)"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(directory):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.isfile(filepath):
                    total_size += os.path.getsize(filepath)
        return total_size / (1024 * 1024)  # MBë¡œ ë³€í™˜


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸš€ D2SA VLM-SAM í†µí•© ì‹¤í—˜ ì‹œì‘")
    print("=" * 80)
    
    # ì‹¤í—˜ ì„¤ì • (train.pyì™€ ë™ì¼í•œ ê²½ë¡œ ì‚¬ìš©)
    D2SA_ROOT = "/root/datasets/D2SA"
    annotation_file = os.path.join(D2SA_ROOT, "D2S_amodal_augmented.json")
    image_dir = os.path.join(D2SA_ROOT, "images")
    output_dir = f"./outputs/d2sa_experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    max_samples = 50  # ë©”ëª¨ë¦¬ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ 50ê°œë¡œ ì œí•œ (Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì „ì²´)
    
    # ì‹¤í—˜ ê°ì²´ ìƒì„±
    experiment = D2SAExperiment(
        annotation_file=annotation_file,
        image_dir=image_dir,
        output_dir=output_dir,
        max_samples=max_samples
    )
    
    try:
        # ì‹¤í—˜ ì‹¤í–‰
        success = experiment.run_experiment()
        
        if success:
            # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
            experiment.create_summary_report()
            
            print(f"\nğŸ‰ D2SA ì‹¤í—˜ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
            print(f"ğŸ“Š ìì„¸í•œ ë‚´ìš©ì€ {os.path.join(output_dir, 'README.md')}ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print(f"\nâŒ ì‹¤í—˜ ì‹¤í–‰ ì‹¤íŒ¨")
    
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì‹¤í—˜ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ ì§€ê¸ˆê¹Œì§€ì˜ ê²°ê³¼ëŠ” {output_dir}ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == '__main__':
    main()
